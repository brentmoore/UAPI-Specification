# Preparing For The Future

> Draft 


The IT industry is constantly changing. With the advent of cloud computing, software as a service, and other emerging technologies computing at BYU will soon look significantly different from what it does today. OIT and its campus partners need to be positioning themselves to be prepared for what is coming. The purpose of this document is to outline the preparations OIT is making to prepare for a new generation of applications and underlying technologies. The major focus of this document is the evolution of sharing data between systems. 

## Where We Are Now
OIT uses a mix of approaches to provide access to data between applications. 

![image of current state](
    https://www.lucidchart.com/publicSegments/view/b6ba20ce-ad11-47e3-879c-60206f0a0240/image.png)


Traditionally applications have shared data through direct database access. This model presents a number of problems:

- The consuming and providing systems are tightly coupled. Changes to the data model of the shared data must be coordinated with all consuming systems in order to prevent unintended consequences. 

- The consuming system must understand the internal business processes of the providing system. This includes the data model and business logic around the data the consuming system requires. Changes to the business processes of the providing system do not automatically propagate to the consuming systems. 

- Direct data access is usually limited to relational databases. New types of data stores are not as easily accessible for consuming systems.

- Cloud based purchased software systems typically use APIs or other similar technologies for data integration.  

- Access policies are very course grained. Access control is at the table level at best and usually at the database schema level. This greatly increases the potential for abuse of access and increases the potential reach of an intruder in a compromised system into other systems.

A variation of direct data access is the use of feeds of data extracted from the providing systems. There are two types of extracts in use: general purpose and custom. General purpose data extracts are generated by the providing system for use by any consuming system that requires access to data. Custom extracts are created specifically for a consuming system. These feeds help isolate the consuming systems from changes in the providing system. Data extracts solve some of the problems with direct data access but also present some issues of their own:

- Data within the extract is only as current as the last time the extract was run. Depending upon the source system the data in the extract may be hours or days behind.

- Access policies to general purpose extracts is "all or nothing". A system that has access to the extract has access to all data within the extract. This requires the extracts to be limited in scope or the source system to provide multiple extracts with varying levels of data sensitivity.

- Custom extracts can limit the data provided on a system by system basis. Each extract is manually created and maintained, increasing the coupling of the providing and consuming systems.

Because of the issues outlined above direct database access and data feeds should be avoided whenever possible. While they may be enticing the long term implications outweigh any short term gains. 

Nearly a decade ago OIT started the process of moving away from direct data access and toward the use of APIs for data sharing between applications. APIs solve a number of the problems with the two above approaches in that they isolate the business logic from the consuming systems and the data returned by the API call is typically real time. APIs also allow for consuming systems to safely update the providing system if they are given appropriate access. Over the years OIT has been able to provide a large number of APIs for use by consuming systems. As our experience with APIs has matured we have found a number of problems with our current approach:

- The current set of APIs provide access to the internal domain models of the providing systems. Consumers may have to understand the internal models of a number of systems to accomplish their work. This results in consuming systems being tightly coupled to the providing systems. Any change in the internal model of the providing system may cause changes to the APIs provided and cause consuming systems to have to adjust in order to account for the differences.

- Access policies are providing system dependent. Consuming systems requiring data from multiple providing systems must navigate multiple access policy implementations. 

As BYU prepares to move on from older technologies and embrace the opportunities provided by the changes in the IT industry a new approach is necessary for the sharing of data between dependent systems. 

## OIT's Application Data Access Strategy

In the past few years OIT has been actively working on new approaches to the problem of sharing data between systems. Taken together the results of these efforts provide the direction necessary to move toward a future where campus systems are capable of getting the information they require in a timely and efficient fashion while solving a number of the issues with our current practices. 

> **Facades**  
>The IT industry has long relied upon the use of **facades** to divide complex systems into sub systems that communicate through well known interfaces while isolating the details of each sub system from those it interacts with. Facades provide a level of abstraction that reduces coupling between the provider and consumer systems. This allows providers of the facade to change the underlying details of a system without impacting the consumers of those systems. OIT's strategy for sharing data relies heavily on this approach. 

OIT's application data sharing strategy can be visualized in the following diagram:

![OIT Application Data Access Strategy](https://www.lucidchart.com/publicSegments/view/61ee01bf-25be-44b9-bcbb-dcfcb6cca442/image.png)

### Domains

BYU OIT has adopted [Domain Driven Design (DDD)](https://en.wikipedia.org/wiki/Domain-driven_design)(Evans, E 2004) as a guide for how we model systems and the interactions between systems. Domains are a central part of DDD. In the DDD vocabulary a domain is "A sphere of knowledge, influence, or activity." (Evans, 2004, p. 512) In this discussion the term "domain" refers to some aspect of university business implemented in software that has a need to interact with other software systems (other domains) in order to perform some business function. A domain may be the equivalent of the traditional applications we are used to thinking about or it may be a subset of the functions of the application. Domains may be implemented as custom built software or a purchased solution. 

Domains have their own stores of data. Traditionally those data stores were contained in relational databases. Going forward domains are free to choose whatever technologies make sense for their needs. Data from purchased solutions will most likely be accessible only through APIs and other means that they provide. This makes direct access to the data within a domain unwise or even impossible. 

### BYU Business Model

Each domain has an internal model of the data and logic related to the business function it is meant to solve. This internal model may be a generic model designed by the provider of a purchased software package or it may more closely model the actual business of the university. Either way, the specifics of how a domain operates internally should not make its way into the applications that consume the domain’s data. The BYU Business Model provides a level of abstraction isolating the consumers from the details of the internals of the providing domain. This abstraction allows the internal model of the domain to change without impacting the consumers of the domain’s data. The BYU Business Model should be reflected in all interactions with the domain. 

## Accessing Domain Data
![Data Access Between Domains](https://www.lucidchart.com/publicSegments/view/d00ae0aa-9e0e-4a10-bab0-d99c92a38f1e/image.png)

There are four standardized ways to interact with a domain. All interactions should reflect the BYU Business Model for the domain. 

### University API

The University API (UAPI) provides a set of REST API resources that reflect common concepts in the BYU Business Model such as students, instructors, and employees. UAPI specification compliant APIs represent all resources in a standard way to make interaction consistent for consumers. The resources are implemented as a facade on top of domain services and business logic in order to isolate the consumer from changes in the underlying domains. UAPI resources are also the only way an external system can update the underlying domain data. This ensures that security policies and business rules are enforced for all updates to domain data. 

### Events

An event is a notification that something significant has occurred within a domain such as an address has changed, a class has been added by a student, or a grade has been posted. Each event that is raised contains information about the originator of the event and the subject of the event. Consuming applications can create a subscription in the EventHub system to be notified when an event of interest occurs, thus allowing near real time update of the consuming application.   

### Claims

A claim is a true or false statement. Claims provide a way for a consuming system to answer a business question essential to their operation without needing to have access to the business logic or data involved in answering the question. For example, a consuming system can determine if a student has a GPA of 3.0 or above without needing to implement the business logic of GPA calculation or having access to the actual GPA of the student in question. Claims are implemented as standardized REST API calls. 

### Central Data Store

Some applications cannot use APIs and Events to access data. The Central Data Store (CDS) provides a database based facade on top of the domain data designed to meet the needs of these applications. Domains feed data to the Central Data Store in a form compliant with the BYU Business Model. Applications can consume the data using traditional database techniques or through data feeds. How in sync the data is with the domain's data store is domain dependent. Only the providing domain is allowed to update the CDS. Consuming applications that wish to update the domain must do so through the University API or a domain specific API.

## Controlling Access to Domain Data

Access to data is governed by policy. A policy uses attributes about the consumer and the data being requested to determine if access should be granted.  Policies are defined at a high level by the Data Stewards responsible for the specific data involved and implemented in the appropriate technology for the method of access. Policies are expressed in the language of the BYU Business Model. For example, a policy may state that a college may access the class schedule for a student if 1) the student is in one of the majors the college provides, or 2) the student is currently taking a class offered by the college. 

# Getting From Here to There

There is still significant work to do in order to realize OIT's vision for sharing data, including:

- Continuing the implementation of the UAPI resources. Significant work has been done, mostly unseen by consumers as of yet, to prepare the initial resources that are part of the UAPI. The specification has gone through significant refinement as the first generally available resources are being developed. Frameworks have been developed to make the delivery of specification compliant resources easier and faster. Processes around data access are being refined. Feedback from early consumers has been incorporated where possible. As each resource is released the equivalent domain APIs it replaces will be deprecated and consumers of those APIs will be encouraged to move to the corresponding UAPI resources as quickly as their business processes will allow. Once all consumers have been moved the old domain APIs will be shut off. We anticipate each resource will evolve over time to better meet the needs of the consumers of the data. 

- The system driving our Event infrastructure is due for an upgrade. Our EventHub infrastructure has been in place for many years and is showing its age. Advancements in cloud computing, industry standard event specifications, and knowledge gained using our current system will be incorporated in a new and improved event system.

- The claims specification needs to be written and implemented. We have a number of domain APIs that perform the function of claims without the formalization we would like to implement. Standardization will make the use of claims by consumers much more consistent. 

- The Central Data Store needs to evolve. We have our initial CDS implementation in place with some data in it. Expanding the data available, determining access control processes, and deciding upon a permanent technology for our expanding implementation all need to be addressed. 

- Data access policies need to be defined in conjunction with the Data Stewards. Implementation of technologies to enforce the defined policies need to be completed and expanded to all of our data access techniques. 


